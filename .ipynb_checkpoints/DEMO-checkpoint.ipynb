{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak Signal Detection Using Deep Learning\n",
    "\n",
    "### Introduction\n",
    "When monitoring radio frequency (RF) signals, or similar signals from sensors such as biomedical, temperature, etc., we are often interested in detecting certain signal “markers” or features. This can become a challenging problem when the signal-of-interest is degraded by noise. Traditional signal detection methods use a range of techniques such as energy detection, “matched filtering”, or other correlation-based processing techniques using the collected time-series data. Short-duration radio frequency (RF) events can be especially challenging to detect, since the useful data length is finite and long integration times needed to increase the signal relative to the noise is not possible. Weak signals that are also short in duration are some of the most difficult to reliably detect (or even find). In this short tutorial, we walk you through an approach based on using a Concolutional Neural Network (CNN) to tackle the traditional signal processing problem of detecting RF signals in noise.\n",
    "\n",
    "Signal detection theory generally looks at signals embedded in additive white Gaussian noise (AWGN). This type of noise is common in the real world and the assumption makes analysis tractable due to the properties of the noise process. The detection of signals in noise depends on the signal duration, amplitude, and the corresponding noise process. This becomes more difficult if correlated noise, or interfering signals, are also in the same band as the signal you wish to detect.\n",
    "\n",
    "In this tutorial, we will assume no a-priori information about the signals-of-interest. As input data, we will utilize spectrograms computed using a common non-parametric Fast Fourier Transform (FFT) method from input RF time-series data. By taking the problem into the frequency domain, these time-frequency grams, which are 2D representations just like a picture, allow us to visualize the energy of a signal over some pre-determined time duration and frequency bandwidth. In practice, collecting and computing spectrograms over time, allows us to create a spectral monitoring system that can automatically monitor frequency bands for a signal-of-interest.\n",
    "\n",
    "For a single sinusoid in AWGN, finding the frequency bin with the maximum amplitude is a method for estimating signal frequency in a spectrogram. But real-world signals are often more complex, with frequency components that change with time, and creating a generalized signal detection algorithm becomes difficult.\n",
    "\n",
    "### Linear Frequency-Modulated Signals\n",
    "One classic example, is the detection of a linear frequency-modulated (LFM), or chirp, signal. This is a signal that ramps up or down in frequency over some time frame. Its frequency changes with time based on its chirp rate. Chirps are used in many different systems to do frequency response measurements and timing. RADAR systems use chirp signals due to the inherent large time-bandwith product available with coherent processing. Another common use is for automatic room equalization in home theater receivers, since chirps can excite a large frequency swath quickly. Chirps can also be used as “pilot” signals to denote start of an incoming transmission, and more.\n",
    "\n",
    "Figure 1 shows a high-SNR chirp as seen in a grayscale spectrogram (the format we will be using). Since the spectrogram consists of real numbers all > 0, we can map it to a picture file by scaling the values appropriately. So we only need a single grayscale image channel. In this plot, the x axis is time and the y axis is frequency. Brightness is proportional to signal power.\n",
    "\n",
    "\n",
    "<img src=\"images2/figure2.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<div align=\"center\">Fig1. High-SNR chip spectrogram (grayscale).</div>\n",
    "\n",
    "The above chirp in Figure 1 has a high SNR and is easy to detect with traditional algorithms. But when you are monitoring RF environments that contain other “offending” signals and noise, reliable detection becomes difficult. For example, Figure 2 shows an example spectrogram with some pulsed carrier waves (sinusoids) and low-bitrate digital communication BPSK signal embedded in noise. Note, that this collect is over a 4 second window.\n",
    "\n",
    "<img src=\"images2/figure3.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<div align=\"center\">Fig2. Typical of real-world noisy spectrum (x-axis is time, y-axis is frequency).</div>\n",
    "\n",
    "In this spectrogram there is no chirp, just noise and other comms-like signals. This is what “real-world” RF signals look like – combinations of signal classes with different strengths, all embedded in noise. As an exemplar of the problem we will solve, Figure 3 consists of another spectrogram showing noise and interfering signals including a weak chirp signal.\n",
    "\n",
    "<img src=\"images2/figure4.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<div align=\"center\">Fig3. Weak chirp embedded in noise (x-axis is time, y-axis is frequency).</div>\n",
    "\n",
    "In Figure 3 the chirp signal is 7 dB below the noise power in this frequency band. That is, the signal-to-noise-ratio (SNR) for the chirp is -7 dB. It is barely visible to the human eye. Traditional detection methods, without large amounts of integration and/or a prior signal model, fail consistently in detecting a weak signal like this. Moreover, since we have interfering signals that are sharing the same bandwidth as the chirp, the problem becomes even harder.\n",
    "\n",
    "When monitoring RF signals, we want accurate detection of these types of signals, as a human cannot process all the data manually. For example, in the case of intelligent spectral monitoring or cognitive radio, we want something to autonomously analyze extraordinary amounts of signal data all the time. The question arises: Can we design a better process to help detect these weak signals?\n",
    "\n",
    "\n",
    "\n",
    "# Deep Spectral Detection: Data and Network Creation\n",
    "- We will create a two-output convolutional neural network that ingests an image of a time/frequency signal spectrogram. The network will determine whether a chirp signal is present (class 0 - signal) or a chirp signal is NOT present (class 1 - noise).\n",
    "\n",
    "### Starting up DIGITS\n",
    "- We have a pre-configured DIGITS instance set up for use with this tutorial. Click [`HERE`](http://ec2-54-144-82-210.compute-1.amazonaws.com:5000) to start up an instance.\n",
    "\n",
    "- The digits server page should be active. Now we will create the dataset using the gui tools in digits.\n",
    "\n",
    "### Creating DIGITS image database\n",
    "- Goto the left side and click the 'Images' button underneath the 'New Dataset' label. Select the 'Classification' menu option.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot1.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- Select grayscale image type, keep the image size 256x256 and enter the directory where the dataset files are stored. The settings used are shown in the below pic.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot2.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- Name the dataset and click \"create\". The data gen screen will show up\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot3.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- You can wait for the database gen to finish. Then click on the upper left \"DIGITS\" text to go back to the digits main screen. You should see your new dataset at the top. If you click on the dataset again, you will now see the processed data set, the mean image it computed, and links to explore images within the database:\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot4.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### New CNN model creation\n",
    "- Go back to the digits main page and goto the right side and click the 'Images' button underneath the 'New Model' label. Select the 'Classification' menu option.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot5.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- In the New Image Classification Model screen, select the image database to use in the upper left.\n",
    "    - For the model to use, select 'Custom Network' and paste the contents of the following [chirp CNN prototxt](http://datasets.kickview.com:8080/dsd_demo/train_val_digits4_chirp.prototxt) into the window.\n",
    "    - Select Nesterov in the solver type menu and set the learning rate (LR) to 0.001.\n",
    "    - Also click on the Advanced button in the learning tab and select \"Exponential decay\"\n",
    "    - Note we set the validation epoch to 1 so the network validation will be run once every epoch.\n",
    "    - We train for only 5 epochs\n",
    "    \n",
    "<img src=\"images2/Digits_Screenshot6.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- You can also click on the \"Visualize\" button next to the custom network window. This will show you what the network looks like below.\n",
    "    - We started with an AlexNet and pruned the number of fully-connected layers to 2.\n",
    "    - The two fully connected layers were also reduced in size (less neurons).\n",
    "    - Added regularization to aid in a better-trained network.\n",
    "    \n",
    "<img src=\"images2/Vis_Screenshot.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "- Finally name the model and click \"Create\". The training screen will show up next with the ongoing training plots.\n",
    "    - In the below plot, you can see the network is unable to learn. The loss curve never decreases.\n",
    "    - This is part of the hyperparameter search space that needs to be explored in order to get a model to train well. We will iterate on the model next.\n",
    "    \n",
    "<img src=\"images2/Digits_Screenshot7.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- After training is complete, click the \"Clone job\" button at the top right. This will create an exact copy of the model for iterating.\n",
    "    - For this experiment, increase the learning rate to 0.008.\n",
    "    - Number of epochs is upped to 7\n",
    "    - Click create (Digits will allow the same model name)\n",
    "    \n",
    "<img src=\"images2/Digits_Screenshot8.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- CONGRATULATIONS, you have trained your Convolutional Neural Network! Digits saves a copy of the network model at each epoch (it's one of the training parameters), so we can go back and analyze any epoch of the training process.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot9.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### What can I do with this thing?\n",
    "- Well, you can test it out on a couple of the training images just for grins. The classification accuracy will be high, but this is just an example:\n",
    "- Go to the bottom of the model page and click on the 'Upload image' in the 'Test a Single Image' section. Although not generally a good practice, let's select one of the images used in training just to see the visualization available in Digits.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot10.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "- Next check the 'Show visualizations and statistics' box. Then click the 'Classify One' button.\n",
    "- The model is run over the image with the classification results up top. The bottom plots show the activations in each layer of the network.\n",
    "- Here we see the network classifies correctly with a probability of 99.98%.\n",
    "\n",
    "<img src=\"images2/Screenshot13.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Generalization on New Signals\n",
    "\n",
    "### Test Set \n",
    "- A test data set is provided with 500-1000 positive and negative examples The test set will be used to determine the generalization cability of the trained network.\n",
    "- A range of SNRs is used in the test set in order to analyze the network's ability to discriminate low and high SNR signals. In doing so, you can come up with a probability of detection (PD) and a probability of false alarm (PFA) metrics for subset of signal strengths.\n",
    "- We wont be using digits here! We will run a python script.\n",
    "\n",
    "### Download saved network model\n",
    "- Go back to digits and the network model just trained. Under the 'Trained Models' section, you can download the network during the epoch times that digits saved off the network weights. If the model trained well, you would typically just download the last epoch.\n",
    "- For this tutorial we have downloaded the model and prepared it. The path to the model is /home/ubuntu/demo/model\n",
    "\n",
    "<img src=\"images2/Screenshot_model.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Python analysis script\n",
    "##### For this tutorial we have already pre-installed the model and test images into digits, the model is located at /home/ubuntu/demo/model \n",
    "\n",
    "- The file 'analyze_spect_dir.py' in the gitlab repo that was downloaded previously is what we will be using. It has `two functions, detection_tst( pos_file_dir, model_dir, pic_type) and false_alarm_tst( neg_file_dir, model_dir, pic_type)`\n",
    "- The functions take in arguments: positive/negative image file directory, caffe model directory, pic type ('jpg' or 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import analyze_spect_dir as ansp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we will run the detection test, which runs all the positive class files through the caffe network model and tallies the detection rate (signal present and detected) and the miss rate (signal present but not detected)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU id used:  0\n",
      "(1, 1, 255, 255)\n",
      "Network load from snapshot_iter_2660.caffemodel\n",
      "Processing 1000 files from /home/ubuntu/demo/testdemo/pos\n",
      "File posex_n6.94db_286.jpg triggered,  neg=0.9, pos=0.1, Miss rate: 1/1000\n",
      "File posex_n3.67db_425.jpg triggered,  neg=1.0, pos=0.0, Miss rate: 2/1000\n",
      "File posex_n6.8db_438.jpg triggered,  neg=1.0, pos=0.0, Miss rate: 3/1000\n",
      "File posex_n5.4db_421.jpg triggered,  neg=0.8, pos=0.2, Miss rate: 4/1000\n",
      "File posex_n6.97db_89.jpg triggered,  neg=0.8, pos=0.2, Miss rate: 5/1000\n",
      "File posex_n6.09db_751.jpg triggered,  neg=0.5, pos=0.5, Miss rate: 6/1000\n",
      "File posex_n5.29db_240.jpg triggered,  neg=0.7, pos=0.3, Miss rate: 7/1000\n",
      "File posex_n6.98db_563.jpg triggered,  neg=1.0, pos=0.0, Miss rate: 8/1000\n",
      "File posex_n6.63db_400.jpg triggered,  neg=0.7, pos=0.3, Miss rate: 9/1000\n",
      "File posex_n6.75db_611.jpg triggered,  neg=1.0, pos=0.0, Miss rate: 10/1000\n",
      "File posex_n5.84db_692.jpg triggered,  neg=0.6, pos=0.4, Miss rate: 11/1000\n",
      "Final PD: 98.9%, Pmiss: 1.1%\n"
     ]
    }
   ],
   "source": [
    "ansp.detection_tst('/home/ubuntu/demo/testdemo/pos', '/home/ubuntu/demo/model', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the above has completed you can see that the network has a decent detection probabilty, but all the cases it cannot detect have SNR = -5 dB!\n",
    "- We can fine tune the fully-connected layers of the network to do better at lower SNRs. (TBD)\n",
    "- Next run the false alarm test. Here we input the negative test examples and see how many of these trigger a positive classification of a chirp present (i.e. a false detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU id used:  0\n",
      "(1, 1, 255, 255)\n",
      "Network load from snapshot_iter_2660.caffemodel\n",
      "Processing 1000 files from /home/ubuntu/demo/testdemo/neg\n",
      "File negex_164.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 1/1000\n",
      "File negex_269.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 2/1000\n",
      "File negex_807.jpg triggered,  neg=0.2, pos=0.8, False alarm rate: 3/1000\n",
      "File negex_762.jpg triggered,  neg=0.0, pos=1.0, False alarm rate: 4/1000\n",
      "File negex_371.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 5/1000\n",
      "File negex_480.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 6/1000\n",
      "File negex_455.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 7/1000\n",
      "File negex_592.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 8/1000\n",
      "File negex_304.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 9/1000\n",
      "File negex_196.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 10/1000\n",
      "File negex_299.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 11/1000\n",
      "File negex_31.jpg triggered,  neg=0.2, pos=0.8, False alarm rate: 12/1000\n",
      "File negex_209.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 13/1000\n",
      "File negex_92.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 14/1000\n",
      "File negex_194.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 15/1000\n",
      "File negex_284.jpg triggered,  neg=0.2, pos=0.8, False alarm rate: 16/1000\n",
      "File negex_702.jpg triggered,  neg=0.5, pos=0.5, False alarm rate: 17/1000\n",
      "File negex_210.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 18/1000\n",
      "File negex_487.jpg triggered,  neg=0.1, pos=0.9, False alarm rate: 19/1000\n",
      "File negex_914.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 20/1000\n",
      "File negex_74.jpg triggered,  neg=0.5, pos=0.5, False alarm rate: 21/1000\n",
      "File negex_161.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 22/1000\n",
      "File negex_607.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 23/1000\n",
      "File negex_664.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 24/1000\n",
      "File negex_713.jpg triggered,  neg=0.1, pos=0.9, False alarm rate: 25/1000\n",
      "Final PFA: 2.5%\n"
     ]
    }
   ],
   "source": [
    "ansp.false_alarm_tst('/home/ubuntu/demo/testdemo/neg', '/home/ubuntu/demo/model', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The PFA of the classifier is << 1% !\n",
    "- Now you have a way to determine the classification strength of newly trained networks (of this type)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the network model\n",
    "- One way to fine tune the model is to create another training set with very low SNRs, around -4 to -8 dB.\n",
    "- Copy this image training set over and make a new database in digits for this low SNR dataset.\n",
    "- Clone the trained classification model in digits so we can train it again using the new dataset.\n",
    "- In the \"Pretrained model\" window, you can enter the snapshot .caffemodel that you saved off from the initial training. This serves as the initialization of the network which should already have good weights.\n",
    "- Make the learning rate much smaller (/10 or /100) so the network cannot unlearn too much.\n",
    "- Train on the low SNR data set for a handful of epochs. See if the network is able to learn more about low SNR cases.\n",
    "- After training, you would import your new dataset and test it using ansp.detection_tst, for this tutorial we have once again sone this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU id used:  0\n",
      "(1, 1, 255, 255)\n",
      "Network load from snapshot_iter_135.caffemodel\n",
      "Processing 1000 files from /home/ubuntu/demo/testdemo/pos\n",
      "File posex_n6.7db_709.jpg triggered,  neg=0.6, pos=0.4, Miss rate: 1/1000\n",
      "File posex_n6.94db_286.jpg triggered,  neg=0.8, pos=0.2, Miss rate: 2/1000\n",
      "File posex_n3.67db_425.jpg triggered,  neg=0.9, pos=0.1, Miss rate: 3/1000\n",
      "File posex_n6.8db_438.jpg triggered,  neg=0.9, pos=0.1, Miss rate: 4/1000\n",
      "File posex_n5.4db_421.jpg triggered,  neg=0.9, pos=0.1, Miss rate: 5/1000\n",
      "File posex_n6.97db_89.jpg triggered,  neg=0.6, pos=0.4, Miss rate: 6/1000\n",
      "File posex_n6.98db_563.jpg triggered,  neg=0.9, pos=0.1, Miss rate: 7/1000\n",
      "File posex_n6.75db_611.jpg triggered,  neg=1.0, pos=0.0, Miss rate: 8/1000\n",
      "Final PD: 99.2%, Pmiss: 0.8%\n"
     ]
    }
   ],
   "source": [
    "ansp.detection_tst('/home/ubuntu/demo/testdemo/pos', '/home/ubuntu/demo/model/finetunelow', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the tuned model, the network improves slightly on classifying low-SNR chirp signals (About 30%) while still classifying correctly on higher SNR examples.\n",
    "- However, this secondary training with low-SNR also decreased the false-alarm rate (from 2.5% to 1.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU id used:  0\n",
      "(1, 1, 255, 255)\n",
      "Network load from snapshot_iter_135.caffemodel\n",
      "Processing 1000 files from /home/ubuntu/demo/testdemo/neg\n",
      "File negex_164.jpg triggered,  neg=0.5, pos=0.5, False alarm rate: 1/1000\n",
      "File negex_585.jpg triggered,  neg=0.2, pos=0.8, False alarm rate: 2/1000\n",
      "File negex_933.jpg triggered,  neg=0.2, pos=0.8, False alarm rate: 3/1000\n",
      "File negex_762.jpg triggered,  neg=0.0, pos=1.0, False alarm rate: 4/1000\n",
      "File negex_455.jpg triggered,  neg=0.2, pos=0.8, False alarm rate: 5/1000\n",
      "File negex_304.jpg triggered,  neg=0.1, pos=0.9, False alarm rate: 6/1000\n",
      "File negex_666.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 7/1000\n",
      "File negex_284.jpg triggered,  neg=0.1, pos=0.9, False alarm rate: 8/1000\n",
      "File negex_283.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 9/1000\n",
      "File negex_487.jpg triggered,  neg=0.1, pos=0.9, False alarm rate: 10/1000\n",
      "File negex_38.jpg triggered,  neg=0.3, pos=0.7, False alarm rate: 11/1000\n",
      "File negex_161.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 12/1000\n",
      "File negex_609.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 13/1000\n",
      "File negex_664.jpg triggered,  neg=0.4, pos=0.6, False alarm rate: 14/1000\n",
      "File negex_713.jpg triggered,  neg=0.1, pos=0.9, False alarm rate: 15/1000\n",
      "Final PFA: 1.5%\n"
     ]
    }
   ],
   "source": [
    "ansp.false_alarm_tst('/home/ubuntu/demo/testdemo/neg', '/home/ubuntu/demo/model/finetunelow', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To temper the network changes, we would need to\n",
    "    - train with more noise examples\n",
    "    - freeze the CNN layer weights during this fine tuning so the network does not change too much.\n",
    "- Here the secondary training has made too much of a swing.\n",
    "- Although note that the network performance is asymmetric, as we gained 14% of detection probability in trade for 10% of false alarm rate with this simple example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
