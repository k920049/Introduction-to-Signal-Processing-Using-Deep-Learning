{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Signal Processing Using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many resources for learning how to use Deep Learning to process imagery. However, very few resources exist to demonstrate how to process data from other sensors such as acoustic, siesmic, radio, or radar. In this tutorial, we will introduce some basic methods for utilizing a Convolutional Neural Network (CNN) to process Radio Frequency (RF) signals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Before we begin, let's verify [WebSockets](http://en.wikipedia.org/wiki/WebSocket) are working on your system.  To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell.  \n",
    "\n",
    "You will know the lab is processing when you see a solid circle in the top-right of the window that looks like this: ![](jupyter_executing.png)\n",
    "Otherwise, when it is idle, you will see the following: ![](jupyter_idle.png)\n",
    "For troubleshooting, please see [Self-paced Lab Troubleshooting FAQ](https://developer.nvidia.com/self-paced-labs-faq#Troubleshooting) to debug the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_pi = 2*3.14159"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to signal detection\n",
    "When monitoring radio frequency (RF) signals, or similar signals from sensors such as biomedical, temperature, etc., we are often interested in detecting certain signal identifying features. This can become a challenging problem when the signal-of-interest is degraded by noise. Traditional signal detection methods use a range of techniques such as energy detection, “matched filtering”, or other correlation-based processing techniques. Short-duration radio frequency (RF) events can be especially challenging to detect, since the useful data length is limited and long integration times are not possible. Weak signals that are short in duration are some of the most difficult to detect. We will walk you through a simple approach using a Convolutional Neural Network (CNN) to tackle the traditional signal processing problem of detecting signals in noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little background information\n",
    "Signal detection theory often assumes that a signal is corupted with additive white Gaussian noise (AWGN). This type of noise is common in the real world and the assumption makes analysis tractable. The detection of a signal in noise depends on the signal duration, amplitude, and the corresponding noise process. This becomes more difficult if interfering signals are also in the same band as the signal you wish to detect. Real-world signals often have frequency components that change with time, and creating a generalized signal detection algorithm becomes difficult. We will look at one of these types of signals - Linear Frequency-Modulated (LFM) signals. In a follow-on tutorial we will explore Frequency-Hopped (FH) signals and multi-signal detection scenarios. \n",
    "\n",
    "In this tutorial, we will utilize spectrograms, which are 2D representations just like a picture, computed from simulated Radio Frequency (RF) data. Trasforming the data into the frequency vs. time domain (i.e., spectrogram), allows us to visualize the energy of a signal over some pre-determined time duration and frequency bandwidth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Frequency-Modulated Signals\n",
    "A linear frequency-modulated (LFM), or chirp, signal is a signal that ramps up or down in frequency over some time frame. Its frequency changes with time based on its chirp rate. Chirps are used in many different systems for frequency response measurements and timing. RADAR systems use chirp signals due to the inherent large time-bandwith product available with coherent processing. Another common use is for automatic room equalization in home theater receivers, since chirps can excite a large frequency swath quickly. Chirps can also be used as “pilot” signals to denote the start of an incoming transmission, and more.\n",
    "\n",
    "Figure 1 shows a high-SNR chirp as seen in a grayscale spectrogram. Since the spectrogram consists of real numbers, all > 0, we can map it to a picture file by scaling the values appropriately. So we only need a single grayscale image channel. In this plot, the x axis is time and the y axis is frequency. Brightness is proportional to signal power.\n",
    "\n",
    "<img src=\"images2/figure2.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<div align=\"center\">Fig1. High-SNR chip spectrogram (grayscale).</div>\n",
    "\n",
    "The above chirp (Figure 1) has a high SNR and is easy to detect with traditional signal processing algorithms. But when the environment contains other signals and noise, reliable detection becomes more difficult. Figure 2 shows an example spectrogram with some pulsed carrier waves (sinusoids) and a low-bitrate digital communication BPSK signal embedded in noise.\n",
    "\n",
    "<img src=\"images2/figure3.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<div align=\"center\">Fig2. Multiple signals and noise (x-axis is time, y-axis is frequency).</div>\n",
    "\n",
    "In Figure 2 there is no chirp signal, just noise and other signals. This is similar to what “real-world” RF signals look like – combinations of signal classes with different strengths, all embedded in noise. Figure 3 consists of another spectrogram showing noise, interfering signals, and a weak chirp signal.\n",
    "\n",
    "<img src=\"images2/figure4.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<div align=\"center\">Fig3. Weak chirp embedded in noise with other signals (x-axis is time, y-axis is frequency).</div>\n",
    "\n",
    "In Figure 3 the chirp signal is several dB below the noise power in this frequency band. In fact, the signal-to-noise-ratio (SNR) for the chirp is -7 dB. Note that it is barely visible to the human eye. Traditional detection methods, without large amounts of integration and/or a prior signal information, fail consistently in detecting a weak signal like this. Moreover, since we have interfering signals that are sharing the same bandwidth as the chirp, the problem becomes even harder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is this good for?\n",
    "When monitoring RF signals, we want accurate detection of these types of signals, as a human cannot visually inspect all the data manually. For example, in the case of intelligent spectral monitoring or cognitive radio, we want something to autonomously analyze extraordinary amounts of signal data all the time. The question arises: Can we design a better process to help detect these weak signals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Spectral Detection: Data and Network Creation\n",
    "We will create a two-output convolutional neural network that ingests a time-frequency spectrogram. The network will determine whether a chirp signal is present (class 0 - signal) or a chirp signal is NOT present (class 1 - noise). We have provided a training data set (i.e., RF Spectrograms) to use for training.\n",
    "\n",
    "### Starting up DIGITS\n",
    "We have a pre-configured DIGITS instance set up for use with this tutorial. Click [`HERE`](/digits/) to start up an instance.\n",
    "\n",
    "The DIGITS server page should be active. Now we will create the dataset using the gui tools in DIGITS.\n",
    "\n",
    "### Creating DIGITS spectrogram database\n",
    "- Goto the left side and click the 'Images' button underneath the 'New Dataset' label. Select the 'Classification' menu option.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot1.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- Select grayscale image type, keep the image size 256x256 and enter the directory `/home/ubuntu/demo/traindemo`. The settings used are shown in the picture below.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot2.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- Name the dataset and click \"create\". The data gen screen will show up\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot3.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- After the  data generation process has finished, click on the upper left \"DIGITS\" application title to go back to the DIGITS main screen. You should see your new dataset at the top. If you click on the dataset again, you will now see the processed data set, the mean spectrogram image it computed (all black), and links to explore spectrogram images within the database. Click on the button to display the data and explore the spectrograms. \n",
    "\n",
    "<img src=\"images2/Digits_Screenshot4.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "### New CNN model creation\n",
    "- Go back to the DIGITS main page. On the right side of the page select 'Images' underneath 'New Model'. Select the 'Classification' menu option.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot5.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- In the New Image Classification Model screen, select the image database to use in the upper left.\n",
    "    - For the model to use, select 'Custom Network' and paste the contents of the following [chirp CNN prototxt](http://datasets.kickview.com:8080/dsd_demo/train_val_digits4_chirp.prototxt) into the window.\n",
    "    - Select Nesterov in the solver type menu and set the learning rate (LR) to 0.001.\n",
    "    - Also click on the Advanced button in the learning tab and select \"Exponential decay\"\n",
    "    - Note we set the validation epoch to 1 so the network validation will be run once every epoch.\n",
    "    - We train for only 5 epochs\n",
    "    \n",
    "<img src=\"images2/Digits_Screenshot6.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- You can also click on the \"Visualize\" button next to the custom network window. This will show you what the network looks like below.\n",
    "    - We started with an AlexNet and pruned the number of fully-connected layers to 2.\n",
    "    - The two fully connected layers were also reduced in size (fewer neurons).\n",
    "    - We sdded regularization to aid in a better-trained network.\n",
    "    \n",
    "<img src=\"images2/Vis_Screenshot.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "- Finally name the model and click \"Create\". The training screen will show up next with the ongoing training plots.\n",
    "    - In the plot below, you can see the network was unable to learn - i.e., the loss curve never decreased.\n",
    "    - Selecting the right learning rate is part of the hyperparameter search space that needs to be explored in order to get a model to train well. Next, we will iterate on the model.\n",
    "    \n",
    "<img src=\"images2/Digits_Screenshot7.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- After training is complete, click the \"Clone job\" button at the top right. This will create an exact copy of the model for iterating.\n",
    "    - For this next experiment, increase the learning rate to 0.008.\n",
    "    - Number of epochs is increased to 7 or 8.\n",
    "    - Click create (DIGITS will allow the same model name)\n",
    "    \n",
    "<img src=\"images2/Digits_Screenshot8.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- CONGRATULATIONS, you have trained your Convolutional Neural Network! DIGITS saves a copy of the network model at each epoch (it's one of the training parameters), so we can go back and analyze, or export, a model from any epoch of the training process.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot9.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "### What can I do with this thing?\n",
    "- Now, you can try it out on a couple traaining spectrograms just for fun. The classification accuracy will be high, but this is just an quick sanity check.\n",
    "- Go to the bottom of the model page and find 'Test a single image' and enter the path to the file '/home/ubuntu/demo/traindemo/pos/posex_0.01db_2061.jpg'. Although it's not a good practice in general to test with data from the training set, this let's us see the visualization features available in DIGITS.\n",
    "\n",
    "<img src=\"images2/Digits_Screenshot10.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "- Make sure to check the 'Show visualizations and statistics' box. Then, click on the 'Classify One' button.\n",
    "- The feed forward computation using our trained model is computed using the spectrogram we selected for input. The plots show the activations in each layer of the network.\n",
    "- You should see the network classify correctly with a probability of approximately 99.98%.\n",
    "\n",
    "<img src=\"images2/Screenshot13.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Generalization on New Signals\n",
    "\n",
    "### Using a test dataset \n",
    "A test data set is provided with 500-1000 positive and negative examples. The test set will be used to determine the generalization cability of the trained network. A range of SNR values are used in the test set in order to analyze the network's ability to discriminate low and high SNR signals. In doing so, you can come up with a probability of detection (PD) and a probability of false alarm (PFA) metrics for a subset of signal strengths. We wont be using DIGITS here! We will run a python script.\n",
    "\n",
    "### Download saved network model\n",
    "- In DIGITS, under the 'Trained Models' section, we can download the network wights and parameters for any epoch during training. If the model trained well, you would typically just download from the last epoch. For this tutorial, we have downloaded the model and prepared it for you. The path to the model is /home/ubuntu/demo/model\n",
    "\n",
    "<img src=\"images2/Screenshot_model.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Python analysis script\n",
    "##### Note: We have already pre-installed the trained network model and test images.\n",
    "\n",
    "- The file 'analyze_spect_dir.py' is provided. It has `two functions, detection_tst( pos_file_dir, model_dir, pic_type) and false_alarm_tst( neg_file_dir, model_dir, pic_type)`\n",
    "- The functions take in arguments: positive/negative image file directory, caffe model directory, pic type ('jpg' or 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import analyze_spect_dir as ansp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we will run the detection test, which runs all the positive class files through the caffe network model and tallies the detection rate (signal present and detected) and the miss rate (signal present but not detected).\n",
    "- Note: Processing may take a few minutes, so be patient for the output to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ansp.detection_tst('/home/ubuntu/demo/testdemo/pos', '/home/ubuntu/demo/model', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After the above script has completed, you will see that the network has a relatively good detection probabilty, but most of the cases it cannot detect have low SNR < -5 dB.\n",
    "- We will go back and fine tune the network to do better at lower SNR in the next section.\n",
    "- Next, run the false alarm test script below. Here we input the negative test examples and see how many of them trigger a positive classification (i.e. a false detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ansp.false_alarm_tst('/home/ubuntu/demo/testdemo/neg', '/home/ubuntu/demo/model', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The probability-of-false-alarm (PFA) should be less than a few percent. \n",
    "- Note that this is one way to determine the classification strength of newly trained networks (of this type)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the network model\n",
    "Now, let's look at a way to fine tune our model using an additional training dataset with very low SNRs, around -4 to -8 dB. Although we have provided this dataset for you, the steps you would take in DIGITS are listed here for educational purposes:\n",
    "- Copy this image training set over and make a new database in DIGITS for this low SNR dataset.\n",
    "- Clone the trained classification model in DIGITS so we can train it again using the new dataset.\n",
    "- In the \"Pretrained model\" window, you can enter the snapshot .caffemodel that you saved off from the initial training. This serves as the initialization of the network which should already have good weights.\n",
    "- Make the learning rate much smaller (/10 or /100) so the network cannot \"unlearn\" too much.\n",
    "- Train on the low SNR data set for a handful of epochs. See if the network is able to improve.\n",
    "- After training, you would import your new dataset and test it using ansp.detection_tst. For this tutorial we have done this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ansp.detection_tst('/home/ubuntu/demo/testdemo/pos', '/home/ubuntu/demo/model/finetunelow', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With the provided tuned model, the network improves slightly on classifying low-SNR chirp signals while still classifying correctly on higher SNR examples.\n",
    "- As we will see next, this secondary training with low-SNR also decreased the false-alarm rate (from 2.5% to 1.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ansp.false_alarm_tst('/home/ubuntu/demo/testdemo/neg', '/home/ubuntu/demo/model/finetunelow', 'jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To further improve the network, we could\n",
    "    - train with more noise examples\n",
    "    - freeze the CNN layer weights during this fine tuning so the network does not change too much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Lab Summary\n",
    "\n",
    "Following the steps outlined in this tutorial, you can create a detector for other signal types. For example, if you go to www.blog.kickview.com you can see an example using frequency hopped signals. \n",
    "\n",
    "This tutorial demonstrated detection using only two categories. It is not hard to extend this method to multiple categories by changing the model. We will demonstrate how to do this in the next tutorial. \n",
    "\n",
    "If you would like to download this lab for later viewing, it is recommend you go to your browsers File menu (not the Jupyter notebook file menu) and save the complete web page.  This will ensure the images are copied down as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
