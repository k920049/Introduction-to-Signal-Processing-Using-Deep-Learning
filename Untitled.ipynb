{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n"
     ]
    }
   ],
   "source": [
    "# Markov Reward Process\n",
    "\n",
    "# hyperparameters\n",
    "probability = tf.constant([[0.0, 0.5, 0.0, 0.0, 0.0, 0.5, 0.0],\n",
    "                          [0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.2],\n",
    "                          [0.0, 0.0, 0.0, 0.6, 0.4, 0.0, 0.0],\n",
    "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                          [0.2, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0],\n",
    "                          [0.1, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0],\n",
    "                          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]], dtype=tf.float32)\n",
    "\n",
    "discount_factor = 0.0\n",
    "\n",
    "reward = tf.transpose(tf.constant([-2.0, -2.0, -2.0, 10.0, 1.0, -1.0, 0.0], dtype=tf.float32))\n",
    "reward = tf.reshape(reward, shape=[7, 1])\n",
    "identity = tf.constant(value=np.identity(7), dtype=tf.float32)\n",
    "print(reward.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1)\n",
      "[[ -2.90815711]\n",
      " [ -1.55006909]\n",
      " [  1.12482727]\n",
      " [ 10.        ]\n",
      " [  0.62413591]\n",
      " [ -2.08255959]\n",
      " [  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "first = identity - 0.5 * probability\n",
    "value = tf.matmul(tf.matrix_inverse(first), reward)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(value.shape)\n",
    "    print(value.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n"
     ]
    }
   ],
   "source": [
    "# Markov Decision Process\n",
    "policy = tf.constant([[0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0],\n",
    "                     [0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5],\n",
    "                     [0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0],\n",
    "                     [0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0],\n",
    "                     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]], dtype=tf.float32)\n",
    "\n",
    "probability_transition = tf.constant([[0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "                                     [0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                                     [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                                     [0.2, 0.4, 0.4, 0.0, 0.0],\n",
    "                                     [0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "                                     [0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "                                     [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                                     [0.0, 0.0, 0.0, 0.0, 0.0]], dtype=tf.float32)\n",
    "\n",
    "reward_transition = tf.constant([2.0, -2.0, 10.0, 1.0, -1.0, -1.0, 0.0, 0.0], dtype=tf.float32)\n",
    "reward_transition = tf.transpose(reward_transition)\n",
    "reward_transition = tf.reshape(reward_transition, shape=[8, 1])\n",
    "identity = tf.constant(np.identity(8), dtype=tf.float32)\n",
    "\n",
    "discount_factor = 0.5\n",
    "print(identity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.28897357]\n",
      " [  1.15589333]\n",
      " [ 10.        ]\n",
      " [  2.62357426]\n",
      " [ -2.        ]\n",
      " [ -2.        ]\n",
      " [  1.2281369 ]\n",
      " [  0.        ]]\n",
      "[[ 2.45627403]\n",
      " [ 0.57794666]\n",
      " [ 6.31178713]\n",
      " [-2.        ]\n",
      " [ 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "second = tf.matmul(probability_transition, policy)\n",
    "second = discount_factor * second\n",
    "second = identity - second\n",
    "\n",
    "action_reward = tf.matmul(tf.matrix_inverse(second), reward_transition)\n",
    "status_reward = tf.matmul(policy, action_reward)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(action_reward.eval())\n",
    "    print(status_reward.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
